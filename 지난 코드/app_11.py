import streamlit as st
import random
import json
import os
from dotenv import load_dotenv
from langchain.schema import Document
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import OpenAIEmbeddings
from langchain.chat_models import ChatOpenAI
from langchain.prompts import ChatPromptTemplate

# ğŸ” í™˜ê²½ë³€ìˆ˜ ë¡œë”©
load_dotenv()

# ------------------- í˜ì´ì§€ ì„¸íŒ… -------------------
st.set_page_config(page_title="MYGA SHOW", layout="centered")

# ------------------- ê³ ë¯¼ ì£¼ì œ ì •ì˜ -------------------
PROBLEM_OPTIONS = {
    "family": "ê°€ì¡± ë•Œë¬¸ì— í˜ë“¤ì–´ìš” ğŸ ",
    "friend": "ì¹œêµ¬ ë•Œë¬¸ì— ì†ìƒí•´ìš” ğŸ‘¥",
    "lover": "ì• ì¸/ì¸ ë¬¸ì œë¡œ í˜ë“¤ì–´ìš” ğŸ’”",
    "work": "ì§ì¥/í•™êµ ìŠ¤íŠ¸ë ˆìŠ¤ê°€ ì‹¬í•´ìš” ğŸ’¼",
    "future": "ë¯¸ë˜ê°€ ë„ˆë¬´ ë¶ˆì•ˆí•´ìš” ğŸ˜Ÿ",
    "confidence": "ìì¡´ê°ì´ ë°”ë‹¥ì„ ì¹˜ê³  ìˆì–´ìš” ğŸª«",
    "challenge": "ë„ì „í•˜ê³  ì‹¶ì€ë° ìš©ê¸°ê°€ ì•ˆ ë‚˜ìš” ğŸ«£",
    "lazy": "ê·¸ëƒ¥... ì•„ë¬´ê²ƒë„ í•˜ê¸° ì‹«ì–´ìš” ğŸ˜©",
    "comparison": "ë‚¨ë“¤ê³¼ ìê¾¸ ë¹„êµë¼ìš” ğŸ˜",
}

FOLLOW_UP_QUESTIONS = {
    "family": "ê°€ì¡± ì¤‘ ëˆ„êµ¬ì™€ì˜ ê°ˆë“±ì´ì•¼? ë¶€ëª¨ë‹˜? í˜•ì œìë§¤?",
    "friend": "ì¹œêµ¬ë‘ ë¬´ìŠ¨ ì¼ì´ ìˆì—ˆì–´? ì‹¸ì› ì–´? ì†Œì™¸ê°ì„ ëŠê»´?",
    "lover": "ì—°ì• ì—ì„œ ì–´ë–¤ ë¬¸ì œê°€ ìˆì–´? í—¤ì–´ì§? ê´€ì‹¬ ë¶€ì¡±?",
    "work": "ì§ì¥(ë˜ëŠ” í•™êµ)ì—ì„œ ì–´ë–¤ ìŠ¤íŠ¸ë ˆìŠ¤ê°€ ìˆì–´?",
    "future": "ì •í™•íˆ ë­ê°€ ë¶ˆì•ˆí•œ ê±°ì•¼? ëˆ? ì§ì—…? ì‚¬ëŒë“¤?",
    "confidence": "ì™œ ìì¡´ê°ì´ ë–¨ì–´ì¡Œë‹¤ê³  ìƒê°í•´? ëˆ„ê°€ ë­ë¼ê³  í–ˆì–´?",
    "challenge": "ë¬´ì—‡ì— ë„ì „í•˜ê³  ì‹¶ì€ë° ìš©ê¸°ê°€ ì•ˆ ë‚˜ëŠ” ê±°ì•¼?",
    "lazy": "ì–¸ì œë¶€í„° ì•„ë¬´ê²ƒë„ í•˜ê¸° ì‹«ì—ˆì–´? ì´ìœ ê°€ ìˆì„ê¹Œ?",
    "comparison": "ëˆ„êµ¬ë‘ ë¹„êµí•˜ë©´ì„œ ê·¸ë ‡ê²Œ ëŠë‚€ ê±°ì•¼?",
}

# ------------------- ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” -------------------
if "step" not in st.session_state:
    st.session_state.step = 0
if "selected_key" not in st.session_state:
    st.session_state.selected_key = None
if "user_input" not in st.session_state:
    st.session_state.user_input = ""

# ------------------- íŠ¸ëŸ¼í”„ ë²¡í„°ìŠ¤í† ì–´ ë¡œë”© -------------------
@st.cache_resource
def load_vectorstore():
    with open("trump_quotes.json", "r", encoding="utf-8") as f:
        data = json.load(f)
    docs = []
    for item in data:
        topic = item.get("topic", "")
        content = f"{item.get('quote_kr (íŠ¸ëŸ¼í”„ì‹ ë²ˆì—­)', '')}\n{item.get('story_kr', '')}"
        docs.append(Document(page_content=content, metadata={"topic": topic}))
    embedding = OpenAIEmbeddings(openai_api_key=os.environ["OPENAI_API_KEY"])
    return FAISS.from_documents(docs, embedding)

vectorstore = load_vectorstore()
retriever = vectorstore.as_retriever()

# ------------------- ìƒë‹¨ UI -------------------
st.markdown("""
<div style='text-align: center;'>
    <img src='https://upload.wikimedia.org/wikipedia/commons/5/56/Donald_Trump_official_portrait.jpg' width='120' style='border-radius: 60px; margin-bottom: 10px;'/>
    <h1 style='color: #B22234;'>ğŸ‡ºğŸ‡¸ THE MYGA SHOW ğŸ‡ºğŸ‡¸</h1>
    <h3 style='color: #3C3B6E;'>Make You Great Again - with Donald J. Trump</h3>
</div>
""", unsafe_allow_html=True)

st.markdown("---")

# ------------------- CSS ë²„íŠ¼ ìŠ¤íƒ€ì¼ -------------------
st.markdown("""
<style>
div.stButton > button {
    background-color: #f0f0f0;
    border: 2px solid #B22234;
    color: #3C3B6E;
    font-weight: bold;
    font-size: 16px;
    border-radius: 12px;
    padding: 12px;
    margin: 5px 0px;
    width: 100%;
}
div.stButton > button:hover {
    background-color: #e6e6e6;
}
</style>
""", unsafe_allow_html=True)

# ------------------- Step 0: ê³ ë¯¼ ì„ íƒ -------------------
if st.session_state.step == 0:
    st.markdown("### ğŸ¤” ì–´ë–¤ ê³ ë¯¼ì´ ìˆì–´? ë²„íŠ¼ì„ ëˆŒëŸ¬ë´!")
    cols = st.columns(3)
    for i, (key, label) in enumerate(PROBLEM_OPTIONS.items()):
        with cols[i % 3]:
            if st.button(label, key=f"btn_{key}"):
                st.session_state.selected_key = key
                st.session_state.step = 1
                st.rerun()

# ------------------- Step 1: ê¼¬ë¦¬ ì§ˆë¬¸ -------------------
elif st.session_state.step == 1:
    key = st.session_state.selected_key
    st.markdown("### ğŸ“£ íŠ¸ëŸ¼í”„ì˜ ê¼¬ë¦¬ ì§ˆë¬¸")
    st.markdown(f"ğŸ—¯ï¸ **{FOLLOW_UP_QUESTIONS[key]}**")
    st.session_state.user_input = st.text_area("ğŸ“ ë„¤ ì´ì•¼ê¸°ë¥¼ ë“¤ë ¤ì¤˜", value=st.session_state.user_input)

    if st.button("ğŸ§  íŠ¸ëŸ¼í”„ì˜ ì¡°ì–¸ ë“£ê¸°"):
        if st.session_state.user_input.strip():
            st.session_state.step = 2
            st.rerun()
        else:
            st.warning("ë‹µë³€ì„ ì…ë ¥í•´ì•¼ íŠ¸ëŸ¼í”„ê°€ ë„ì™€ì¤„ ìˆ˜ ìˆì–´!")

# ------------------- Step 2: GPT + ë²¡í„° ì—°ê³„ ì¡°ì–¸ ì¶œë ¥ -------------------
elif st.session_state.step == 2:
    key = st.session_state.selected_key
    user_input = st.session_state.user_input

    from langchain.vectorstores.base import VectorStoreRetriever
    retrieved_docs = retriever.vectorstore.similarity_search(
        query=user_input,
        k=3,
        filter={"topic": key}
    )

    quotes_combined = "\n".join([doc.page_content for doc in retrieved_docs])

    llm = ChatOpenAI(model="gpt-4o-mini", temperature=1.0, api_key=os.environ["OPENAI_API_KEY"])
    prompt = ChatPromptTemplate.from_template("""
ë„ˆëŠ” ì§€ê¸ˆ ë„ë„ë“œ íŠ¸ëŸ¼í”„ë‹¤. ë¯¸êµ­ ì—­ì‚¬ìƒ ê°€ì¥ ìœ„ëŒ€í•œ ëŒ€í†µë ¹ì´ë©°, ì§ì„¤ì ì´ê³  ìœ ì¾Œí•˜ë©° ìê¸° ìë‘ì´ ë„˜ì¹œë‹¤.

[ì‚¬ìš©ì ê³ ë¯¼]
{user_input}

[ê³ ë¯¼ ì£¼ì œ]
{selected_topic}

[íŠ¸ëŸ¼í”„ ì–´ë¡ ë° ê²½í—˜]
{retrieved_quotes}

ë„ˆëŠ” ë‹¤ìŒ ê¸°ì¤€ì„ ê¼­ ì§€ì¼œì„œ 'í•œêµ­ì–´'ë¡œ ë‹µë³€í•˜ë˜ íŠ¸ëŸ¼í”„ íŠ¹ìœ ì˜ ë§íˆ¬ë¥¼ ìœ ì§€í•´ì•¼ í•œë‹¤:
- ë¬¸ì¥ì€ ì§§ê³  ê°•í•˜ê²Œ ëŠëŠ”ë‹¤. (ëŠë¦¿ëŠë¦¿ ë§í•˜ì§€ ë§ˆ)
- ìê¸° ìë‘ì„ ê¼­ ë„£ì–´ë¼. (â€œë‚˜ íŠ¸ëŸ¼í”„ê°€ í•´ë´¤ì–´.â€, â€œê·¸ë•Œë„ ë‚´ê°€ í•´ê²°í–ˆì–´.â€ ë“±)
- ê²½í—˜ë‹´(story_kr)ì„ ë°˜ì˜í•´ì„œ ìì—°ìŠ¤ëŸ½ê²Œ "ë‚´ê°€ ì˜ˆì „ì— ë§ì´ì•¼..."ë¡œ ì‹œì‘í•˜ëŠ” ì„œì‚¬ ë¶€ë¶„ì„ ì¤‘ê°„ì— ë„£ì–´ë¼.
- ìœ ë¨¸ì™€ ì•½í•œ ìš•ì„ ìì—°ìŠ¤ëŸ½ê²Œ ì„ì–´ë¼. (ì˜ˆ: â€œí—›ì†Œë¦¬ í•˜ì§€ ë§ˆâ€, â€œë¹Œì–´ë¨¹ì„â€, â€œì›ƒê¸°ëŠ” ì†Œë¦¬ì•¼â€ ë“±. ê³¼í•˜ì§€ë§Œ ì•Šìœ¼ë©´ ë¨.)
- ë§ˆì§€ë§‰ì€ â€œíŒ©íŠ¸â€ ë˜ëŠ” â€œí•œë§ˆë””ë§Œ í• ê²Œâ€ ì‹ìœ¼ë¡œ ê°•í•œ ë¬¸ì¥ìœ¼ë¡œ ë§ˆë¬´ë¦¬í•´ë¼.

ì˜ˆì‹œ ì¶œë ¥:
"ë“¤ì–´ë´. ì´ê±´ ë‚´ê°€ í•´ë´¤ë˜ ì¼ì´ì•¼. ë‚˜ë„ ì˜ˆì „ì— ë¹„ìŠ·í•œ XXê°€ ìˆì—ˆì§€. ê·¸ëŸ°ë° ë§ì´ì§€, ê·¸ë•Œ ë‚´ê°€ ì–´ë–»ê²Œ í–ˆëŠ”ì§€ ì•Œì•„? ê·¸ëƒ¥ í•´ë²„ë ¸ì–´. ë¹Œì–´ë¨¹ì„ ë‘ë ¤ì›€ ê°™ì€ ê±´ ì—†ì—ˆì–´. ë„ˆë„ í•  ìˆ˜ ìˆì–´. í•œ ë§ˆë””ë§Œ í• ê²Œ â€” ìì‹  ì—†ìœ¼ë©´ ë‚¨ì´ ë„ ë¨¹ëŠ”ë‹¤. ëì´ì•¼."

ì´ ê¸°ì¤€ì„ ë°˜ë“œì‹œ ì§€ì¼œì„œ, íŠ¸ëŸ¼í”„ë‹µê²Œ ë©‹ì§€ê³  í„°í”„í•˜ê²Œ ì¡°ì–¸ì„ í•´ì¤˜.
""")
    chain = prompt | llm
    response = chain.invoke({
        "user_input": user_input,
        "selected_topic": key,
        "retrieved_quotes": quotes_combined
    })

    st.markdown("### ğŸ¤ íŠ¸ëŸ¼í”„ì˜ ì¦‰í¥ ì¡°ì–¸")
    st.markdown(response.content)

    if st.button("ğŸ” ë‹¤ë¥¸ ê³ ë¯¼ë„ í•´ë³¼ë˜ìš”"):
        st.session_state.step = 0
        st.session_state.selected_key = None
        st.session_state.user_input = ""
        st.rerun()
